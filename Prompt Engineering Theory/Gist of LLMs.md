# What is a Language Model?

A **language model** is a *probability distribution over a sequence of words* ‚Äî essentially, it predicts the likelihood of the next word given the previous ones.  
> _Definition from Wikipedia_

---

## üìà Understanding It with an Example

Imagine the sentence:

> **"LangChain is a __________"**

Now, let‚Äôs fill in that blank. Some possible candidates might be:

1. Framework  
2. Library  
3. Banana  
4. Fruit

A language model assigns probabilities to each possible next word. For example:

- **Framework**: 0.99  
- **Library**: 0.80  
- **Banana**: 0.10  
- **Fruit**: 0.10  

Since **"Framework"** has the highest probability, the model chooses that as the next word. This is how language models work ‚Äî predicting the most likely next token based on the given context.

---

## üßÆ Mathematically Speaking

A language model estimates:

```
P(x‚Çú‚Çä‚ÇÅ | x‚Çú, x‚Çú‚Çã‚ÇÅ, ..., x‚ÇÅ)
```

Where `x‚Çú‚Çä‚ÇÅ` is the next word, and `V` is the vocabulary of all possible words.  
![Language Model](./Images/language_model.png)

---

## üí° Everyday Applications

Language models power the autocomplete suggestions you see in:

- Gmail
- Text messages
- Google Search

They're constantly calculating the most probable next word ‚Äî just like your phone's predictive typing!

---

## ü§ñ What About Large Language Models (LLMs)?

A **Large Language Model (LLM)** is simply a language model trained on massive datasets ‚Äî books, websites, code, conversations, etc. Because of this large training data, LLMs:

- Are better at understanding context
- Make more accurate next-word predictions
- Can complete entire thoughts, paragraphs, or even generate code

However, since they **only predict what comes next**, LLMs can sometimes **hallucinate** ‚Äî i.e., generate plausible-sounding but incorrect information.

---

## ‚úÖ TL;DR

- Language models predict the next word based on probability.
- LLMs do the same, but better, thanks to massive training data.
- They‚Äôre behind features like autocomplete and chatbots.
- Sometimes, they guess wrong ‚Äî that‚Äôs a hallucination!

---