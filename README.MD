## This is me learning, unlearning and relearning Langchain from Eden Marco's Udemy Course

Course Link - [LangChain- Develop LLM powered applications with LangChain](https://www.udemy.com/course/langchain/?couponCode=KEEPLEARNING)

### Utilizing this project properly
So, here is the folder structure and the starter file from each of the folder
>.vscode
> Code Interpeter
  > main.py
> Documentation Helper
  > main.py
> Ice breaker
  > ice_breaker.py
> Ice breaker project
  > app.py
> intro-to-vector-dbs
  > main.py
> Langchain Thoery Notes
> LLM Applications in Production
> Model Context Protocol
> Prompt Engineering Theory
> react-langchain
  > main.py
> vectorstore-in-memory
  > main.py
> .gitignore
> README.MD


Now, if you want to learn about langchain through this repo, the order in which you have to go is
Ice breaker -> Ice breaker project -> react-langchain -> intro-to-vector-dbs -> vectorstore-in-memory -> Documentation Helper -> Code Interpreter

How to start using each file:
1. Ice breaker: Navigate inside the Ice breaker folder using cd command and then enter ./.venv/Scripts/activate to activate the virtual environment and then run python ice_breaker.py
2. Ice breaker project: Navigate inside the Ice breaker project folder using cd command and then enter ./.venv/Scripts/activate to activate the virtual environment and then run python app.py to open the HTML, CSS and flask application
3. react-langchain: Navigate inside the react-langchain project folder using cd command and then enter ./.venv/Scripts/activate to activate the virtual environment and then run python main.py.
4. intro-to-vector-dbs: Navigate inside the intro-to-vector-dbs project folder using cd command and then enter ./.venv/Scripts/activate to activate the virtual environment and then run python main.py
5. vectorstore-in-memory: Navigate inside the vectorstore-in-memory project folder using cd command and then enter ./.venv/Scripts/activate to activate the virtual environment and then run python main.py
6. Documentation Helper: Navigate inside the Documentation Helper project folder using cd command and then enter ./.venv/Scripts/activate to activate the virtual environment and then run streamlit run main.py to open the website.
7. Code Interpreter: Navigate inside the Code Interpreter project folder using cd command and then enter ./.venv/Scripts/activate to activate the virtual environment and then run python main.py.

---

### **Setting Up Pipenv for Multiple Subfolders with Isolated `.venv` Environments**

This is how to ensure that each subfolder has its own **Pipenv virtual environment** stored inside the subfolder (`.venv`), making it easy to distinguish environments. When activated, the environment name (same as the subfolder) will appear in parentheses before the terminal path.

---

#### **1. Remove Any Root-Level Pipenv Configuration (If Applicable)**  
If your root project folder contains a `Pipfile` or `Pipfile.lock`, Pipenv might try to associate all subfolders with the same virtual environment. To prevent this:
- **Delete** `Pipfile` and `Pipfile.lock` from the root manually.
- Or, if a virtual environment is already linked, remove it using:
  ```bash
  pipenv --rm
  ```

---

#### **2. Create a Separate Virtual Environment in Each Subfolder**  
Navigate to the subfolder where you want to create an isolated virtual environment and run:
```bash
cd ./subfoldername/
pipenv shell
```
This will:

âœ… Create a **Pipfile** in that subfolder.  
âœ… Create a `.venv` **inside** the subfolder to store dependencies.  
âœ… Activate the virtual environment, displaying **(subfoldername)** before the path in the terminal.

If you want to **ensure the `.venv` is created inside the subfolder**, set:
```powershell
$env:PIPENV_VENV_IN_PROJECT = "1"
```
and then activate the pipenv shell:
```powershell
pipenv shell
```
Sometimes running the above 2 commands together works in creating the venv effectively.
```powershell
$env:PIPENV_VENV_IN_PROJECT = "1"
pipenv shell
```

#### **3. Activating the Virtual Environment in Any Subfolder**  
Once inside the subfolder, activate its virtual environment with:
```powershell
./.venv/Scripts/activate  # Windows (PowerShell)
```
This ensures the correct environment is used, and the terminal prompt should update to show `(subfoldername)` before the path.

---

#### **4. Switching Between Subfolder Environments**
1. **Deactivate the current environment** before switching:
   ```bash
   deactivate
   ```
2. **Navigate to another subfolder and activate its environment:**
   ```bash
   cd ../another-subfolder/
   ./.venv/Scripts/activate  # Windows
   ```

---

#### **5. Verify the Active Virtual Environment**
To confirm which virtual environment is currently active:
```powershell
pipenv --venv
```
This should return the path inside the current subfolder:
```
Folder Path\subfoldername\.venv
```

To further verify:
```powershell
echo $env:VIRTUAL_ENV  # PowerShell
```
This should match the `.venv` inside the current subfolder.

---

#### **6. Notes on Virtual Environment Naming**
- The environment name displayed in parentheses **before the path** (`(subfoldername)`) is auto-generated by Pipenv.
- If the folder name contains dashes (`-`), Pipenv may replace them with underscores (`_`), but the environment remains correct.

---

#### **7. Sometimes venv is not detected right**
- Sometimes some libraries even when venv is activated and the library is present in the `venv/lib` folder, it shows it can't find 
because the vscode ide is taking a different interpreter for the file.
- So, in that cases you have to enter: `ctrl + shift + p` and enter `Python: Select Interpreter` and then if you can't find the venv 
you are looking for: click on  `Enter Interpreter Path` and go to `.venv/Scripts/python.exe` in your folder where `.venv` is residing and  and choose `Select Interpreter` to resolve the issue

---

#### **Final Checklist**
âœ” Each subfolder has its **own** `.venv` (not shared).  
âœ” Activating the environment shows **(subfoldername)** before the terminal path.  
âœ” `pipenv --venv` correctly displays the `.venv` path inside the subfolder.  
âœ” Switching between environments works without conflicts.  

---

### ğŸ§­ Why LangGraph?

When developing agents using **LangChain (ReAct)** or simple **LLM chaining**, there are a few major pain points:

- âŒ **Unreliable execution**  
- ğŸ” Can end up in **infinite loops**  
- âš ï¸ Prone to **errors** due to:
  - Ambiguous task definitions  
  - Poorly defined tools  
  - Over-flexibility (leaving too much to the LLMâ€™s discretion)  

---

### ğŸ’¡ The Problem

Relying **too much on the LLM** to figure out the next action or the sequence of steps introduces unpredictability.

As developers, we often **want control** â€” to define:

- ğŸ›£ï¸ The **flow** of the agent  
- ğŸ”„ Whether cycles are allowed  
- âœ… How each tool is used  
- ğŸš« What is **not allowed** during execution  

---

### ğŸ”— Enter: **LangGraph**

LangGraph solves these challenges by letting you build **agent workflows as graphs**, where:

- ğŸ”¹ **Nodes** = Actions, tools, or reasoning steps  
- ğŸ”¹ **Edges** = Controlled transitions between them  
- ğŸ” You can define **cycles**, but with **full control**  
- ğŸ¯ Enables **structured agent behavior** while still using LLMs for reasoning  

> ğŸ§  **LangGraph = Flexibility + Reliability** â€” A powerful combo for robust agent systems.

Check out the [LangGraph course on Udemy](https://www.udemy.com/course/langgraph/?couponCode=KEEPLEARNING) to dive deeper.
---

### Langsmith Setup

If you want to setup Langsmith tracing for your project, follow these steps:
1. Setup env variables:
    ```bash
    LANGCHAIN_TRACING_V2=true  # to start tracing
    LANGCHAIN_API_KEY = ""  # API Key created in Langsmith
    LANGCHAIN_PROJECT=Ice Breaker  # Project Name where you want tracing to happen
    ```
2. Load those environment variables in files where Agents are implemented (AgentExecutor) as vscode doesn't directly take env variables
3. Refer this documentation of setting up langsmith for more info: [Langmsith setting up](https://docs.smith.langchain.com/)
4. Benefits: 
    - You will be able to trace everything from initial prompt to tool outputs etc
    - You will get a fair idea about latency, cost etc
    - You can optimize quickly based on the information present there

---

### ğŸ“š Resources for Building with LLMs

---

#### 1. ğŸ” Prompt Library â€” *LangChain Hub*

Explore a wide variety of **battle-tested prompts** across use cases like:

- âœ… Entity extraction  
- ğŸ’¬ SQL generation  
- ğŸ‘¨â€ğŸ’» Code generation  
- ğŸ“š RAG pipelines  
- ğŸ§  Prompts optimized per LLM vendor (since prompts that work well on one model may not work on another)

â†’ Try them out and experiment here:  
ğŸ‘‰ [LangChain Hub](https://smith.langchain.com/hub)

---

#### 2. ğŸ§© Text Chunking â€” *Text Splitter Playground*

When using **RAG**, it's crucial to chunk your text meaningfully so that:

- ğŸ“Œ Each chunk retains context and meaning on its own  
- ğŸ“ You choose the **right `chunk_size` and `chunk_overlap`**  
- ğŸ§  Chunks donâ€™t lose semantics during retrieval

This is usually trial and error. But LangChain built a playground for this:  
ğŸ‘‰ [Text Splitter Playground](https://langchain-text-splitter.streamlit.app/)

---

#### 3. ğŸ†š LlamaIndex vs LangChain

Both frameworks are used to build LLM applications. Here's a quick comparison:

| Feature            | **LlamaIndex**                | **LangChain**                  |
|--------------------|-------------------------------|--------------------------------|
| Focus              | Data-centric / RAG-heavy      | General-purpose LLM orchestration |
| RAG Capabilities   | ğŸ”¥ Very strong                 | âœ… Evolving and improving       |
| Tooling            | Great for structured data     | Great for agents + integrations |

You can choose based on your projectâ€™s needs â€” or combine them both!